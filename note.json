{
   "paragraphs":[
      {
         "title":"Getting Data ",
         "text":"%sh\npwd\ncurl -sSL -O \"https://raw.githubusercontent.com/hortonworks-gallery/zeppelin-notebooks/master/2D8S9EJ23/training.csv\" \ncat training.csv | tail -n 5\n\ncurl -sSL -O \"https://raw.githubusercontent.com/hortonworks-gallery/zeppelin-notebooks/master/2D8S9EJ23/transactions.json\"\n\nhadoop fs -mkdir -p /tmp/ccdemo\nhadoop fs -copyFromLocal -f training.csv /tmp/ccdemo/\nhadoop fs -copyFromLocal -f transactions.json /tmp/ccdemo/",
         "user":"dsxuser",
         "dateUpdated":"2018-03-16T21:52:42+0000",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{

            },
            "editorSetting":{
               "language":"sh",
               "editOnDblClick":false
            },
            "editorMode":"ace/mode/sh",
            "title":true
         },
         "settings":{
            "params":{

            },
            "forms":{

            }
         },
         "results":{
            "code":"SUCCESS",
            "msg":[
               {
                  "type":"TEXT",
                  "data":"/user-home/1002/DSX_Projects/Fraud\n1,19123,7.20,9.50,11.20\n1,19123,0.90,1.10,16.60\n1,19123,11.40,0.90,1.30\n1,19123,1.80,15.60,0.80\n1,19123,0.30,2.04,17.50\n"
               }
            ]
         },
         "apps":[

         ],
         "jobName":"paragraph_1521233620455_-508002420",
         "id":"20180316-205340_1466880704",
         "dateCreated":"2018-03-16T20:53:40+0000",
         "dateStarted":"2018-03-16T21:46:40+0000",
         "dateFinished":"2018-03-16T21:46:40+0000",
         "status":"FINISHED",
         "progressUpdateIntervalMs":500,
         "focus":true,
         "$$hashKey":"object:30"
      },
      {
         "title":"Read Raw Transactions",
         "text":"val transaction = spark.read.format(\"json\").option(\"inferSchema\", \"true\").load(\"/tmp/ccdemo/transactions.json\")\n\ntransaction.show\ntransaction.printSchema\n\ntransaction.createOrReplaceTempView(\"trans\")\n\n/*transaction.groupBy(\"accountNumber\", \"merchantType\")\n  .pivot(\"merchantType\")\n  .avg(\"amount\".cast(DoubleType))\n*/\n",
         "user":"dsxuser",
         "dateUpdated":"2018-03-16T21:51:44+0000",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{
               "0":{
                  "graph":{
                     "mode":"table",
                     "height":309.023,
                     "optionOpen":false
                  }
               }
            },
            "editorSetting":{
               "language":"scala"
            },
            "editorMode":"ace/mode/scala",
            "title":true,
            "editorHide":false,
            "tableHide":false
         },
         "settings":{
            "params":{

            },
            "forms":{

            }
         },
         "results":{
            "code":"SUCCESS",
            "msg":[
               {
                  "type":"TEXT",
                  "data":"transaction: org.apache.spark.sql.DataFrame = [accountNumber: string, accountType: string ... 10 more fields]\n+-------------+-----------+------+--------+---------+-------------+---------+---------+----------+-----------------+------------------+--------------------+\n|accountNumber|accountType|amount|currency|ipAddress|isCardPresent| latitude|longitude|merchantId|     merchantType|     transactionId|transactionTimeStamp|\n+-------------+-----------+------+--------+---------+-------------+---------+---------+----------+-----------------+------------------+--------------------+\n|        19123|       VISA|    24|     USD|         |         true|39.914441|-75.01132|      1001|convenience_store| 10011521162000000|       1521162000000|\n|        19124|       VISA|    45|     USD|         |         true|31.914441|-55.01132|      1002|         webstore| 10012221162000000|       1521162000000|\n|        19125|       VISA|    52|     USD|         |         true|31.914441|-75.01132|      1003|       Food_store| 10011521162000000|       1523162000000|\n|        19126|       VISA|    12|     USD|         |         true|21.914441|-15.01132|      1004|        Transport|100122213222000000|       1521262000000|\n+-------------+-----------+------+--------+---------+-------------+---------+---------+----------+-----------------+------------------+--------------------+\n\nroot\n |-- accountNumber: string (nullable = true)\n |-- accountType: string (nullable = true)\n |-- amount: string (nullable = true)\n |-- currency: string (nullable = true)\n |-- ipAddress: string (nullable = true)\n |-- isCardPresent: string (nullable = true)\n |-- latitude: string (nullable = true)\n |-- longitude: string (nullable = true)\n |-- merchantId: string (nullable = true)\n |-- merchantType: string (nullable = true)\n |-- transactionId: string (nullable = true)\n |-- transactionTimeStamp: string (nullable = true)\n\n"
               }
            ]
         },
         "apps":[

         ],
         "jobName":"paragraph_1521148587742_1830063556",
         "id":"20180315-211627_161197296",
         "dateCreated":"2018-03-15T21:16:27+0000",
         "dateStarted":"2018-03-16T21:46:57+0000",
         "dateFinished":"2018-03-16T21:47:07+0000",
         "status":"FINISHED",
         "progressUpdateIntervalMs":500,
         "$$hashKey":"object:31"
      },
      {
         "title":"Display Raw Transactions",
         "text":"%sql\nselect * from trans",
         "user":"dsxuser",
         "dateUpdated":"2018-03-16T21:47:10+0000",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{

            },
            "editorSetting":{
               "language":"sql",
               "editOnDblClick":false
            },
            "editorMode":"ace/mode/sql",
            "title":true
         },
         "settings":{
            "params":{

            },
            "forms":{

            }
         },
         "results":{
            "code":"SUCCESS",
            "msg":[
               {
                  "type":"TABLE",
                  "data":"accountNumber\taccountType\tamount\tcurrency\tipAddress\tisCardPresent\tlatitude\tlongitude\tmerchantId\tmerchantType\ttransactionId\ttransactionTimeStamp\n19123\tVISA\t24\tUSD\t\ttrue\t39.914441\t-75.01132\t1001\tconvenience_store\t10011521162000000\t1521162000000\n19124\tVISA\t45\tUSD\t\ttrue\t31.914441\t-55.01132\t1002\twebstore\t10012221162000000\t1521162000000\n19125\tVISA\t52\tUSD\t\ttrue\t31.914441\t-75.01132\t1003\tFood_store\t10011521162000000\t1523162000000\n19126\tVISA\t12\tUSD\t\ttrue\t21.914441\t-15.01132\t1004\tTransport\t100122213222000000\t1521262000000\n"
               }
            ]
         },
         "apps":[

         ],
         "jobName":"paragraph_1521151671201_456488080",
         "id":"20180315-220751_126031286",
         "dateCreated":"2018-03-15T22:07:51+0000",
         "dateStarted":"2018-03-16T21:47:10+0000",
         "dateFinished":"2018-03-16T21:47:11+0000",
         "status":"FINISHED",
         "progressUpdateIntervalMs":500,
         "$$hashKey":"object:32"
      },
      {
         "title":"Calculate Avg Amount and Standard Dev",
         "text":"%sql\nselect avg(amount), stddev(amount), accountNumber, merchantType from trans group by accountNumber, merchantType",
         "user":"dsxuser",
         "dateUpdated":"2018-03-16T21:47:30+0000",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{

            },
            "editorSetting":{
               "language":"sql"
            },
            "editorMode":"ace/mode/sql",
            "title":true
         },
         "settings":{
            "params":{

            },
            "forms":{

            }
         },
         "results":{
            "code":"SUCCESS",
            "msg":[
               {
                  "type":"TABLE",
                  "data":"avg(CAST(amount AS DOUBLE))\tstddev_samp(CAST(amount AS DOUBLE))\taccountNumber\tmerchantType\n52.0\tNaN\t19125\tFood_store\n12.0\tNaN\t19126\tTransport\n45.0\tNaN\t19124\twebstore\n24.0\tNaN\t19123\tconvenience_store\n"
               }
            ]
         },
         "apps":[

         ],
         "jobName":"paragraph_1521153172963_-707965716",
         "id":"20180315-223252_502205909",
         "dateCreated":"2018-03-15T22:32:52+0000",
         "dateStarted":"2018-03-16T21:47:30+0000",
         "dateFinished":"2018-03-16T21:47:41+0000",
         "status":"FINISHED",
         "progressUpdateIntervalMs":500,
         "$$hashKey":"object:33"
      },
      {
         "title":"Train Model on Zscores",
         "text":"import org.apache.spark.sql.Row\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.ml.classification.ProbabilisticClassifier\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\nimport org.apache.spark.mllib.util.MLUtils\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.sql.types._\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\nimport org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\nimport org.apache.spark.ml.classification.{BinaryLogisticRegressionSummary, LogisticRegression}\n\n// Load training data\n// Add data asset from file system\nval data = spark.read.format(\"csv\").option(\"header\", \"false\").option(\"inferSchema\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"/tmp/ccdemo/training.csv\")\n\n// show schema and dataset\ndata.printSchema\ndata.show\ndata.createOrReplaceTempView(\"data\")\n\n// create feature vector\nval assembler =  new VectorAssembler()\n  .setInputCols(Array(\"_c2\", \"_c3\", \"_c4\"))\n  .setOutputCol(\"features\")\n  \n// assemble a new vector from dataframe\nval df1 = assembler.transform(data).select($\"_c0\".cast(DoubleType).as(\"label\"), $\"features\")\n\n// Split the data into train and test\nval splits = df1.randomSplit(Array(7.0, 3.0), seed = 1234L)\nval (train, test) = (splits(0), splits(1))\n\n// create model\nval model = new LogisticRegression()\n  .setMaxIter(700)\n  .setRegParam(0.1)\n  .setElasticNetParam(0.8)\n  //.setFamily(\"binomial\")\n\n// train model\nval rModel = model.fit(train)\n\n// Print the coefficients and intercepts for logistic regression with multinomial family\n//println(s\"Multinomial coefficients: ${rModel.coefficientMatrix}\")\n//println(s\"Multinomial intercepts: ${rModel.interceptVector}\")",
         "user":"dsxuser",
         "dateUpdated":"2018-03-16T21:52:02+0000",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{

            },
            "editorSetting":{
               "editOnDblClick":false,
               "language":"scala"
            },
            "editorMode":"ace/mode/scala",
            "title":true
         },
         "settings":{
            "params":{
               "rModel.coefficientMatrix":"",
               "rModel.interceptVector":""
            },
            "forms":{

            }
         },
         "results":{
            "code":"SUCCESS",
            "msg":[
               {
                  "type":"TEXT",
                  "data":"import org.apache.spark.sql.Row\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.ml.classification.ProbabilisticClassifier\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\nimport org.apache.spark.mllib.util.MLUtils\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.sql.types._\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\nimport org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\nimport org.apache.spark.ml.classification.{BinaryLogisticRegressionSummary, LogisticRegression}\ndata: org.apache.spark.sql.DataFrame = [_c0: int, _c1: int ... 3 more fields]\nroot\n |-- _c0: integer (nullable = true)\n |-- _c1: integer (nullable = true)\n |-- _c2: double (nullable = true)\n |-- _c3: double (nullable = true)\n |-- _c4: double (nullable = true)\n\n+---+-----+----+----+----+\n|_c0|  _c1| _c2| _c3| _c4|\n+---+-----+----+----+----+\n|  0|19123|0.85|2.05|0.78|\n|  0|19123|0.96|2.05|0.78|\n|  0|19123|1.09|2.05|0.78|\n|  0|19123|0.21|2.05|0.78|\n|  0|19123|0.39|2.05| 1.3|\n|  0|19123|0.08|2.44|0.24|\n|  1|19123|12.0| 2.0| 3.0|\n|  1|19123| 2.1|22.4| 3.1|\n|  1|19123| 8.0| 6.5| 9.7|\n|  0|19123|0.73|2.23|0.43|\n|  0|19123|0.77|2.23| 1.3|\n|  0|19123|1.65|2.05|0.51|\n|  0|19123|0.79|2.05|0.51|\n|  0|19123|0.61|2.05|1.54|\n|  0|19123|0.03|2.05| 1.3|\n|  0|19123|1.43|2.05|1.54|\n|  0|19123|1.37|2.05|1.26|\n|  1|19123| 1.8|15.6| 0.8|\n|  1|19123| 0.3|2.04|17.5|\n|  0|19123|1.61|2.05|0.74|\n+---+-----+----+----+----+\nonly showing top 20 rows\n\nassembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_46d24936795b\ndf1: org.apache.spark.sql.DataFrame = [label: double, features: vector]\nsplits: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] = Array([label: double, features: vector], [label: double, features: vector])\ntrain: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\nmodel: org.apache.spark.ml.classification.LogisticRegression = logreg_4b9312e3edc6\nrModel: org.apache.spark.ml.classification.LogisticRegressionModel = logreg_4b9312e3edc6\n"
               }
            ]
         },
         "apps":[

         ],
         "jobName":"paragraph_1521146792882_-2068547",
         "id":"20180315-204632_128034780",
         "dateCreated":"2018-03-15T20:46:32+0000",
         "dateStarted":"2018-03-16T20:58:35+0000",
         "dateFinished":"2018-03-16T20:59:07+0000",
         "status":"FINISHED",
         "progressUpdateIntervalMs":500,
         "$$hashKey":"object:34"
      },
      {
         "title":"Display Abnormal Transactions",
         "text":"%sql\nselect * from data",
         "user":"dsxuser",
         "dateUpdated":"2018-03-16T01:32:21+0000",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{
               "0":{
                  "graph":{
                     "mode":"multiBarChart",
                     "height":300,
                     "optionOpen":false,
                     "setting":{
                        "multiBarChart":{
                           "stacked":true
                        }
                     },
                     "commonSetting":{

                     },
                     "keys":[
                        {
                           "name":"_c1",
                           "index":1,
                           "aggr":"sum"
                        }
                     ],
                     "groups":[

                     ],
                     "values":[
                        {
                           "name":"_c2",
                           "index":2,
                           "aggr":"max"
                        },
                        {
                           "name":"_c3",
                           "index":3,
                           "aggr":"max"
                        },
                        {
                           "name":"_c4",
                           "index":4,
                           "aggr":"max"
                        }
                     ]
                  },
                  "helium":{

                  }
               }
            },
            "editorSetting":{
               "language":"sql"
            },
            "editorMode":"ace/mode/sql",
            "title":true
         },
         "settings":{
            "params":{

            },
            "forms":{

            }
         },
         "results":{
            "code":"SUCCESS",
            "msg":[
               {
                  "type":"TABLE",
                  "data":"_c0\t_c1\t_c2\t_c3\t_c4\n0\t19123\t0.85\t2.05\t0.78\n0\t19124\t0.96\t2.05\t0.78\n0\t19125\t1.09\t2.05\t0.78\n0\t19126\t0.21\t2.05\t0.78\n0\t19127\t0.39\t2.05\t1.3\n0\t19128\t0.08\t2.44\t0.24\n1\t19129\t12.0\t2.0\t3.0\n1\t19130\t2.1\t22.4\t3.1\n1\t19131\t8.0\t6.5\t9.7\n0\t19132\t0.73\t2.23\t0.43\n0\t19133\t0.77\t2.23\t1.3\n0\t19134\t1.65\t2.05\t0.51\n0\t19135\t0.79\t2.05\t0.51\n0\t19136\t0.61\t2.05\t1.54\n0\t19137\t0.03\t2.05\t1.3\n0\t19138\t1.43\t2.05\t1.54\n0\t19139\t1.37\t2.05\t1.26\n1\t19140\t1.8\t15.6\t0.8\n1\t19141\t0.3\t2.04\t17.5\n0\t19142\t1.61\t2.05\t0.74\n0\t19143\t1.31\t2.05\t1.3\n0\t19144\t1.32\t2.05\t0.51\n0\t19145\t0.95\t2.05\t0.51\n0\t19146\t1.01\t2.05\t1.54\n0\t19147\t0.73\t2.44\t1.54\n0\t19148\t0.06\t2.23\t1.12\n0\t19149\t0.99\t2.23\t0.04\n0\t19150\t1.65\t2.05\t1.22\n0\t19151\t0.09\t2.05\t1.54\n0\t19152\t1.56\t2.05\t0.24\n0\t19153\t1.46\t2.05\t1.3\n0\t19154\t1.57\t2.05\t0.74\n0\t19155\t0.79\t2.05\t1.22\n0\t19156\t0.96\t2.05\t0.78\n0\t19157\t0.06\t2.05\t1.06\n0\t19158\t0.78\t2.05\t1.22\n0\t19159\t0.72\t2.05\t1.22\n0\t19160\t1.9\t2.05\t0.04\n0\t19161\t0.3\t2.05\t1.54\n0\t19162\t0.5\t2.05\t1.26\n1\t19163\t12.0\t2.0\t3.0\n1\t19164\t2.1\t22.4\t3.1\n1\t19165\t8.0\t6.5\t9.7\n1\t19166\t5.9\t2.0\t33.3\n1\t19167\t14.0\t3.3\t4.1\n1\t19168\t1.4\t15.7\t2.0\n1\t19169\t7.2\t9.5\t11.2\n1\t19170\t0.9\t1.1\t16.6\n1\t19171\t11.4\t0.9\t1.3\n1\t19172\t1.8\t15.6\t0.8\n1\t19173\t0.3\t2.04\t10.5\n1\t19174\t22.0\t2.0\t3.0\n1\t19175\t2.1\t22.4\t3.1\n1\t19176\t8.0\t67.5\t19.7\n1\t19177\t5.9\t2.0\t33.3\n1\t19178\t14.0\t3.3\t4.1\n1\t19179\t1.4\t15.7\t2.0\n1\t19180\t7.2\t9.5\t11.2\n1\t19181\t0.9\t1.1\t16.6\n1\t19182\t11.4\t0.9\t1.3\n1\t19183\t1.8\t15.6\t0.8\n1\t19184\t0.3\t2.04\t17.5\n"
               }
            ]
         },
         "apps":[

         ],
         "jobName":"paragraph_1521146827906_774015957",
         "id":"20180315-204707_695743932",
         "dateCreated":"2018-03-15T20:47:07+0000",
         "dateStarted":"2018-03-16T01:32:21+0000",
         "dateFinished":"2018-03-16T01:32:23+0000",
         "status":"FINISHED",
         "progressUpdateIntervalMs":500,
         "$$hashKey":"object:35"
      },
      {
         "text":"%sql\nselect * from data limit 10",
         "user":"dsxuser",
         "dateUpdated":"2018-03-16T01:37:49+0000",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{
               "0":{
                  "graph":{
                     "mode":"table",
                     "height":300,
                     "optionOpen":false
                  },
                  "helium":{

                  }
               }
            },
            "editorSetting":{
               "language":"sql"
            },
            "editorMode":"ace/mode/sql"
         },
         "settings":{
            "params":{

            },
            "forms":{

            }
         },
         "results":{
            "code":"SUCCESS",
            "msg":[
               {
                  "type":"TABLE",
                  "data":"_c0\t_c1\t_c2\t_c3\t_c4\n0\t19123\t0.85\t2.05\t0.78\n0\t19124\t0.96\t2.05\t0.78\n0\t19125\t1.09\t2.05\t0.78\n0\t19126\t0.21\t2.05\t0.78\n0\t19127\t0.39\t2.05\t1.3\n0\t19128\t0.08\t2.44\t0.24\n1\t19129\t12.0\t2.0\t3.0\n1\t19130\t2.1\t22.4\t3.1\n1\t19131\t8.0\t6.5\t9.7\n0\t19132\t0.73\t2.23\t0.43\n"
               }
            ]
         },
         "apps":[

         ],
         "jobName":"paragraph_1521153243009_296472456",
         "id":"20180315-223403_1553925982",
         "dateCreated":"2018-03-15T22:34:03+0000",
         "dateStarted":"2018-03-16T01:37:38+0000",
         "dateFinished":"2018-03-16T01:37:38+0000",
         "status":"FINISHED",
         "progressUpdateIntervalMs":500,
         "$$hashKey":"object:36"
      },
      {
         "title":"Read Model Training Errors",
         "text":"val trainingSummary = rModel.summary\n\n// Obtain the objective per iteration.\nval objectiveHistory = trainingSummary.objectiveHistory\nobjectiveHistory.foreach(loss => println(loss))\n\n// Obtain the metrics useful to judge performance on test data.\n// We cast the summary to a BinaryLogisticRegressionSummary since the problem is a\n// binary classification problem.\nval binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]\n\n// Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\nval roc = binarySummary.roc\nroc.show()\nprintln(binarySummary.areaUnderROC)\n\n// Set the model threshold to maximize F-Measure\nval fMeasure = binarySummary.fMeasureByThreshold\nval maxFMeasure = fMeasure.select(max(\"F-Measure\")).head().getDouble(0)\nval bestThreshold = fMeasure.where($\"F-Measure\" === maxFMeasure)\n  .select(\"threshold\").head().getDouble(0)\nrModel.setThreshold(bestThreshold)\n",
         "user":"dsxuser",
         "dateUpdated":"2018-03-16T01:38:20+0000",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{

            },
            "editorSetting":{
               "language":"scala"
            },
            "editorMode":"ace/mode/scala",
            "title":true
         },
         "settings":{
            "params":{

            },
            "forms":{

            }
         },
         "results":{
            "code":"SUCCESS",
            "msg":[
               {
                  "type":"TEXT",
                  "data":"trainingSummary: org.apache.spark.ml.classification.LogisticRegressionTrainingSummary = org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummary@6529d85b\nobjectiveHistory: Array[Double] = Array(0.6853142072764574, 0.6639616195635891, 0.5750050393648397, 0.5445884891636131, 0.522940588028914, 0.5164224973013938, 0.5155574615210339, 0.5151951004713107, 0.5151480547252311, 0.5151366564476098, 0.5151365016291882, 0.5151364959015732, 0.5151364957884422, 0.5151364957722266)\n0.6853142072764574\n0.6639616195635891\n0.5750050393648397\n0.5445884891636131\n0.522940588028914\n0.5164224973013938\n0.5155574615210339\n0.5151951004713107\n0.5151480547252311\n0.5151366564476098\n0.5151365016291882\n0.5151364959015732\n0.5151364957884422\n0.5151364957722266\nbinarySummary: org.apache.spark.ml.classification.BinaryLogisticRegressionSummary = org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummary@6529d85b\nroc: org.apache.spark.sql.DataFrame = [FPR: double, TPR: double]\n+--------------------+--------------------+\n|                 FPR|                 TPR|\n+--------------------+--------------------+\n|                 0.0|                 0.0|\n|                 0.0|0.047619047619047616|\n|                 0.0| 0.14285714285714285|\n|                 0.0| 0.19047619047619047|\n|                 0.0|  0.2857142857142857|\n|                 0.0| 0.38095238095238093|\n|                 0.0| 0.42857142857142855|\n|                 0.0|  0.5238095238095238|\n|                 0.0|  0.6190476190476191|\n|                 0.0|  0.7142857142857143|\n|                 0.0|  0.7619047619047619|\n|                 0.0|  0.8095238095238095|\n|                 0.0|  0.8571428571428571|\n|                 0.0|  0.9047619047619048|\n|                 0.0|                 1.0|\n|0.037037037037037035|                 1.0|\n| 0.07407407407407407|                 1.0|\n|  0.1111111111111111|                 1.0|\n| 0.14814814814814814|                 1.0|\n| 0.18518518518518517|                 1.0|\n+--------------------+--------------------+\nonly showing top 20 rows\n\n1.0\nfMeasure: org.apache.spark.sql.DataFrame = [threshold: double, F-Measure: double]\nmaxFMeasure: Double = 1.0\nbestThreshold: Double = 0.3427634737856114\nres37: rModel.type = logreg_2a904ea30be0\n"
               }
            ]
         },
         "apps":[

         ],
         "jobName":"paragraph_1521148488146_-527798653",
         "id":"20180315-211448_1720037634",
         "dateCreated":"2018-03-15T21:14:48+0000",
         "dateStarted":"2018-03-16T01:38:20+0000",
         "dateFinished":"2018-03-16T01:38:49+0000",
         "status":"FINISHED",
         "progressUpdateIntervalMs":500,
         "$$hashKey":"object:37"
      },
      {
         "user":"dsxuser",
         "config":{
            "colWidth":12,
            "enabled":true,
            "results":{

            },
            "editorSetting":{
               "language":"scala"
            },
            "editorMode":"ace/mode/scala"
         },
         "settings":{
            "params":{

            },
            "forms":{

            }
         },
         "apps":[

         ],
         "jobName":"paragraph_1521164300078_-304801264",
         "id":"20180316-013820_2136604568",
         "dateCreated":"2018-03-16T01:38:20+0000",
         "status":"READY",
         "progressUpdateIntervalMs":500,
         "$$hashKey":"object:38"
      }
   ],
   "name":"Credit Card Fraud",
   "id":"2D8S9EJ23",
   "angularObjects":{
      "2CYSFF4KX:shared_process":[

      ],
      "2CZ7M5Z1U:shared_process":[

      ],
      "2CZN4E536:shared_process":[

      ],
      "2CXMXB6B9:shared_process":[

      ],
      "2CX1UN2AM:shared_process":[

      ],
      "2CVYP86A3:shared_process":[

      ],
      "2CZPMT4AR:shared_process":[

      ]
   },
   "config":{
      "looknfeel":"default",
      "personalizedMode":"false"
   },
   "info":{

   }
}
